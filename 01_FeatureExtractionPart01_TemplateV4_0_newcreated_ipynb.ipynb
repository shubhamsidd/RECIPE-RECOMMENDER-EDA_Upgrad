{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d1aeeee",
   "metadata": {
    "id": "640bd3f7"
   },
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250afccb",
   "metadata": {},
   "source": [
    "### IMPORTING REQUIRED LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fjAFldderPs-",
   "metadata": {
    "id": "fjAFldderPs-"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master('local').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "LJtN6s0tZvAT",
   "metadata": {
    "id": "LJtN6s0tZvAT"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "p0TOH8GC0cKV",
   "metadata": {
    "id": "p0TOH8GC0cKV"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Basics\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "V_8koIUzZvIa",
   "metadata": {
    "id": "V_8koIUzZvIa"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Import for typecasting columns\n",
    "from pyspark.sql.types import IntegerType,BooleanType,DateType,FloatType,StringType\n",
    "from pyspark.sql.types import ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7IcsDcJLZvlI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "id": "7IcsDcJLZvlI",
    "outputId": "a6a0f59d-13cd-4ead-8637-e8b527a9fcff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-17-0.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f15ea0dfe50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04ed2518",
   "metadata": {
    "id": "04ed2518"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "494d9d27",
   "metadata": {
    "id": "494d9d27"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Basics\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a3d6550",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "id": "5a3d6550",
    "outputId": "787a47e9-a10a-4511-a677-6cc03c1d0def"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-17-0.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f15ea0dfe50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d956d7bf",
   "metadata": {
    "id": "d956d7bf"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Import for typecasting columns\n",
    "from pyspark.sql.types import IntegerType,BooleanType,DateType,FloatType,StringType\n",
    "from pyspark.sql.types import ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "QcaTVH3Cbvlh",
   "metadata": {
    "id": "QcaTVH3Cbvlh"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Property used to format output tables better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652d9b65",
   "metadata": {
    "id": "652d9b65"
   },
   "source": [
    " ## <font color='red'>Task 01: Read the data </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45cb47b",
   "metadata": {
    "id": "d45cb47b"
   },
   "source": [
    "<font color='red'> Ensure you read the data so that all columns are read with the right data type.\n",
    "The \"right\" datatype at this stage are shown in the expected output cell below. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ef807f",
   "metadata": {
    "id": "d4ef807f"
   },
   "source": [
    "<font color='red'>\n",
    "    \n",
    "**Sample input:** \n",
    "This task does not have an input. \n",
    "\n",
    "**Sample output:** \n",
    "Dataframe stored in the variable ```raw_recipes_df```.  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2f1588",
   "metadata": {
    "id": "2a2f1588"
   },
   "source": [
    "![task1.png](attachment:task1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b0c21a",
   "metadata": {
    "id": "c0b0c21a"
   },
   "source": [
    "<font color='red'> We have included some test cases given below. You can use them to check if you have completed the task correctly.  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8a30e9",
   "metadata": {
    "id": "ad8a30e9"
   },
   "source": [
    "### <font color='blue'>Solution to Task 1 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fe11a3",
   "metadata": {
    "id": "d4fe11a3"
   },
   "source": [
    "<font color='blue'>complete the code in the following cell </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dDEynmnkcA_j",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dDEynmnkcA_j",
    "outputId": "978b60af-4147-498a-8445-c1134810f911"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3663cd7f",
   "metadata": {},
   "source": [
    "### Reading data set 1- raw_recipes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e20dae66",
   "metadata": {
    "id": "e20dae66"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Task 01 Cell 1 out of 1\n",
    "\n",
    "raw_recipes_df = spark.read.csv('RAW_recipes_cleaned.csv',inferSchema=True,header=True)\n",
    "                   # argument 1, Add an argument to communicate to the compiler that there is a header in the raw data.\n",
    "                   # argument 2, Add an argument to ask the complier to estimate the data types for all columns. \n",
    "                              \n",
    "\n",
    "# Please forward the exact name of data frames and columns as suggested in the code. \n",
    "# It will ensure that the assert commands function correctly.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210b2adf",
   "metadata": {},
   "source": [
    "### Checking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "QRhpfBnuJuDY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QRhpfBnuJuDY",
    "outputId": "2bcd5f53-2481-47f1-817a-00992c30d2d9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      " |-- minutes: integer (nullable = true)\n",
      " |-- contributor_id: integer (nullable = true)\n",
      " |-- submitted: string (nullable = true)\n",
      " |-- tags: string (nullable = true)\n",
      " |-- nutrition: string (nullable = true)\n",
      " |-- n_steps: integer (nullable = true)\n",
      " |-- steps: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- ingredients: string (nullable = true)\n",
      " |-- n_ingredients: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_recipes_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92203a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-------+--------------+----------+--------------------+--------------------+-------+--------------------+--------------------+--------------------+-------------+\n",
      "|                name|    id|minutes|contributor_id| submitted|                tags|           nutrition|n_steps|               steps|         description|         ingredients|n_ingredients|\n",
      "+--------------------+------+-------+--------------+----------+--------------------+--------------------+-------+--------------------+--------------------+--------------------+-------------+\n",
      "|arriba   baked wi...|137739|     55|         47892|2005-09-16|['60-minutes-or-l...|[51.5, 0.0, 13.0,...|     11|['make a choice a...|autumn is my favo...|['winter squash',...|            7|\n",
      "|a bit different  ...| 31490|     30|         26278|2002-06-17|['30-minutes-or-l...|[173.4, 18.0, 0.0...|      9|['preheat oven to...|this recipe calls...|['prepared pizza ...|            6|\n",
      "|all in the kitche...|112140|    130|        196586|2005-02-25|['time-to-make', ...|[269.8, 22.0, 32....|      6|['brown ground be...|this modified ver...|['ground beef', '...|           13|\n",
      "|  alouette  potatoes| 59389|     45|         68585|2003-04-14|['60-minutes-or-l...|[368.1, 17.0, 10....|     11|['place potatoes ...|this is a super e...|['spreadable chee...|           11|\n",
      "|amish  tomato ket...| 44061|    190|         41706|2002-10-25|['weeknight', 'ti...|[352.9, 1.0, 337....|      5|['mix all ingredi...|my dh's amish mot...|['tomato juice', ...|            8|\n",
      "|apple a day  milk...|  5289|      0|          1533|1999-12-06|['15-minutes-or-l...|[160.2, 10.0, 55....|      4|['combine ingredi...|                    |['milk', 'vanilla...|            4|\n",
      "|aww  marinated ol...| 25274|     15|         21730|2002-04-14|['15-minutes-or-l...|[380.7, 53.0, 7.0...|      4|['toast the fenne...|my italian mil wa...|['fennel seeds', ...|            9|\n",
      "|backyard style  b...| 67888|    120|         10404|2003-07-30|['weeknight', 'ti...|[1109.5, 83.0, 37...|     10|['in a medium sau...|this recipe is po...|['pork spareribs'...|           22|\n",
      "|bananas 4 ice cre...| 70971|    180|        102353|2003-09-10|['weeknight', 'ti...|[4270.8, 254.0, 1...|      8|['crumble cookies...|                    |['chocolate sandw...|            6|\n",
      "|beat this  banana...| 75452|     70|         15892|2003-11-04|['weeknight', 'ti...|[2669.3, 160.0, 9...|     12|['preheat oven to...| from ann hodgman's |['sugar', 'unsalt...|            9|\n",
      "|berry  good sandw...|109439|      5|         49168|2005-01-25|['15-minutes-or-l...|[79.2, 3.0, 58.0,...|      2|['in medium size ...|horseradish is on...|['whole berry cra...|            3|\n",
      "|better than sex  ...| 42198|   1460|         41531|2002-10-03|['weeknight', 'ti...|[734.1, 66.0, 199...|      8|['crush vanilla w...|simple but sexy. ...|['vanilla wafers'...|            7|\n",
      "|better then bush ...| 67547|   2970|         85627|2003-07-26|['weeknight', 'ti...|[462.4, 28.0, 214...|      9|['in a very large...|i'd have to say t...|['great northern ...|           13|\n",
      "|boat house  colla...|107517|    525|        137696|2005-01-03|['time-to-make', ...|[315.8, 0.0, 202....|      7|['put prepared gr...|my boss gave me t...|['collard greens'...|            7|\n",
      "|calm your nerves ...| 39959|      5|         37449|2002-09-10|['15-minutes-or-l...|[8.2, 0.0, 0.0, 0...|      6|['combine herbs',...|this will prove a...|['gentian root', ...|            5|\n",
      "|chicken lickin  g...| 63986|    500|         14664|2003-06-06|['weeknight', 'ti...|[105.7, 8.0, 0.0,...|      5|['dredge pork cho...|here's and old st...|['lean pork chops...|            7|\n",
      "|      chile rellenos| 43026|     45|         52268|2002-10-14|['60-minutes-or-l...|[94.0, 10.0, 0.0,...|      9|['drain green chi...|a favorite from a...|['egg roll wrap',...|            5|\n",
      "|      chinese  candy| 23933|     15|         35268|2002-03-29|['15-minutes-or-l...|[232.7, 21.0, 77....|      4|['melt butterscot...|a little differen...|['butterscotch ch...|            3|\n",
      "|  chinese  chop suey|  8559|     70|          4481|2001-01-27|['weeknight', 'ti...|[395.4, 31.0, 20....|      8|['brown ground me...|easy one-pot dinn...|['celery', 'onion...|            7|\n",
      "|cream  of caulifl...| 23850|    110|          3288|2002-03-28|['lactose', 'week...|[174.2, 4.0, 24.0...|     10|['heat the oil or...|this is a dairy f...|['canola oil', 'o...|           16|\n",
      "+--------------------+------+-------+--------------+----------+--------------------+--------------------+-------+--------------------+--------------------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_recipes_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ba1047d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name',\n",
       " 'id',\n",
       " 'minutes',\n",
       " 'contributor_id',\n",
       " 'submitted',\n",
       " 'tags',\n",
       " 'nutrition',\n",
       " 'n_steps',\n",
       " 'steps',\n",
       " 'description',\n",
       " 'ingredients',\n",
       " 'n_ingredients']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_recipes_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f332ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "231637"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_recipes_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff0d6fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_recipes_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62407b85",
   "metadata": {
    "id": "62407b85"
   },
   "source": [
    "<font color='blue'>Test cases for Task 01</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5b8d8b3",
   "metadata": {
    "id": "a5b8d8b3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Code check cell\n",
    "# Do not edit cells with assert commands\n",
    "# If an error is shown after running this cell, please recheck your code.  \n",
    "\n",
    "assert raw_recipes_df.count() == 231637, \"There is a mistake in reading the data.\"\n",
    "assert len(raw_recipes_df.columns) == 12, \"There is a mistake in reading the data.\"\n",
    "assert raw_recipes_df.schema[\"minutes\"].dataType == IntegerType(), \"The data types have not been read correctly.\"\n",
    "assert raw_recipes_df.schema[\"tags\"].dataType == StringType(), \"The data types have not been read correctly.\"\n",
    "assert raw_recipes_df.schema[\"n_ingredients\"].dataType == IntegerType(), \"The data types have not been read correctly.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbd80be",
   "metadata": {
    "id": "abbd80be"
   },
   "source": [
    " #### <font color='red'>If all test cases pass task 01 ends </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5252aa98",
   "metadata": {},
   "source": [
    "## Data Manipulation and Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d240566",
   "metadata": {
    "id": "8d240566"
   },
   "source": [
    "## Extract ```nutrition``` values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e60b6807",
   "metadata": {
    "id": "e60b6807"
   },
   "outputs": [],
   "source": [
    "# List of nutrition columns\n",
    "\n",
    "nutrition_column_names = ['calories',\n",
    "                          'total_fat_PDV',\n",
    "                          'sugar_PDV',\n",
    "                          'sodium_PDV',\n",
    "                          'protein_PDV',\n",
    "                          'saturated_fat_PDV',\n",
    "                          'carbohydrates_PDV']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383e4450",
   "metadata": {
    "id": "383e4450"
   },
   "source": [
    " ## <font color='red'>Task 02: Extract individual features from the nutrition column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a836d795",
   "metadata": {
    "id": "a836d795"
   },
   "source": [
    "<font color='red'> \n",
    "As read by the spark compiler, the nutrition column is a string column when it should be an array of float values. Each row in the nutrition column contains seven values. Each value represents nutrition information. \n",
    "    \n",
    "    \n",
    "**Your task is to separate the array into seven individual columns.**\n",
    "    \n",
    "Write a code that takes in the nutrition column from ```raw_recipes_df``` dataframe, and extracts individual values into seven different columns named calories, total fat (PDV), sugar (PDV), sodium (PDV), protein (PDV), saturated fat (PDV), and carbohydrates (PDV).\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d47c797",
   "metadata": {
    "id": "7d47c797"
   },
   "source": [
    "<font color='red'>\n",
    "    \n",
    "### **Sample input:** \n",
    "    \n",
    "The image below shows a subset of columns from the ```raw_recipes_df``` dataset. The datatype of the nutrition column is a string.\n",
    " </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c1e1cb",
   "metadata": {
    "id": "b3c1e1cb"
   },
   "source": [
    "![task2.01.png](attachment:task2.01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df30c694",
   "metadata": {
    "id": "df30c694"
   },
   "source": [
    "<font color='red'>\n",
    "    \n",
    "### **Sample Output:** \n",
    "    \n",
    "The image below shows a subset of columns from the ```raw_recipes_df``` dataset after the extraction of nutrition values is completed. The datatype of the individual nutrition column is has to be float.\n",
    " </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f684f24f",
   "metadata": {
    "id": "f684f24f"
   },
   "source": [
    "![task2.03.png](attachment:task2.03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5240146f",
   "metadata": {
    "id": "5240146f"
   },
   "source": [
    "<font color='red'>\n",
    "\n",
    "This task is further divided into two sub tasks \n",
    "    \n",
    "### Task 2.1 \n",
    "    \n",
    "Use string operations to remove the square brackets from the nutrition column. \n",
    "\n",
    "Sample input: nutrition column \n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ac3c26",
   "metadata": {
    "id": "19ac3c26"
   },
   "source": [
    "![task2.01.png](attachment:task2.01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f221977",
   "metadata": {
    "id": "5f221977"
   },
   "source": [
    "<font color='red'>\n",
    "\n",
    "\n",
    "**Sample output:** \n",
    "Nutrition column without the brackets. \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af331b0",
   "metadata": {
    "id": "7af331b0"
   },
   "source": [
    "![task2.02.png](attachment:task2.02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bdc7a5",
   "metadata": {
    "id": "39bdc7a5"
   },
   "source": [
    "<font color='red'>\n",
    "\n",
    "### Task 2.2 \n",
    "    \n",
    "Task 2.2 Split the nutrition column into seven individual columns and cast the new columns to float values. \n",
    "\n",
    "First split the column on using the comma delimiter. Then you can use a for loop to iterate over the column names declared in the variable ```nutrition_column_names```, inside each iteration write a code to extract the value at a specific index of the nutrition array  \n",
    "\n",
    "**Sample input:**\n",
    "Nutrition column without the brackets.\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31435271",
   "metadata": {
    "id": "31435271"
   },
   "source": [
    "![task2.02.png](attachment:task2.02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4655f67c",
   "metadata": {
    "id": "4655f67c"
   },
   "source": [
    "<font color='red'>\n",
    "\n",
    "**Sample output:**\n",
    "Nutrition column split into multiple \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884e23e8",
   "metadata": {
    "id": "884e23e8"
   },
   "source": [
    "![task2.03.png](attachment:task2.03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1c05c0",
   "metadata": {
    "id": "7b1c05c0"
   },
   "source": [
    "<font color='red'> We have included some test cases given below. You can use them to check if you have completed the task correctly.  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da588328",
   "metadata": {
    "id": "da588328"
   },
   "source": [
    "### <font color='blue'>Solution to Task 2 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51ea51c",
   "metadata": {
    "id": "c51ea51c"
   },
   "source": [
    "<font color='blue'>complete the code in the following cell </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Sigz_kecfmFt",
   "metadata": {
    "id": "Sigz_kecfmFt"
   },
   "outputs": [],
   "source": [
    "### prior checking of nutrition column before removing brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "HVA3L9FCfmKN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HVA3L9FCfmKN",
    "outputId": "3e61d8c4-3c52-4178-b987-d8c78c192bbe",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------+\n",
      "|nutrition                                          |\n",
      "+---------------------------------------------------+\n",
      "|[51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]              |\n",
      "|[173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]          |\n",
      "|[269.8, 22.0, 32.0, 48.0, 39.0, 27.0, 5.0]         |\n",
      "|[368.1, 17.0, 10.0, 2.0, 14.0, 8.0, 20.0]          |\n",
      "|[352.9, 1.0, 337.0, 23.0, 3.0, 0.0, 28.0]          |\n",
      "|[160.2, 10.0, 55.0, 3.0, 9.0, 20.0, 7.0]           |\n",
      "|[380.7, 53.0, 7.0, 24.0, 6.0, 24.0, 6.0]           |\n",
      "|[1109.5, 83.0, 378.0, 275.0, 96.0, 86.0, 36.0]     |\n",
      "|[4270.8, 254.0, 1306.0, 111.0, 127.0, 431.0, 220.0]|\n",
      "|[2669.3, 160.0, 976.0, 107.0, 62.0, 310.0, 138.0]  |\n",
      "|[79.2, 3.0, 58.0, 0.0, 0.0, 6.0, 5.0]              |\n",
      "|[734.1, 66.0, 199.0, 10.0, 10.0, 117.0, 28.0]      |\n",
      "|[462.4, 28.0, 214.0, 69.0, 14.0, 29.0, 23.0]       |\n",
      "|[315.8, 0.0, 202.0, 9.0, 6.0, 0.0, 21.0]           |\n",
      "|[8.2, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]                |\n",
      "|[105.7, 8.0, 0.0, 26.0, 5.0, 4.0, 3.0]             |\n",
      "|[94.0, 10.0, 0.0, 11.0, 11.0, 21.0, 0.0]           |\n",
      "|[232.7, 21.0, 77.0, 4.0, 6.0, 38.0, 8.0]           |\n",
      "|[395.4, 31.0, 20.0, 29.0, 51.0, 33.0, 8.0]         |\n",
      "|[174.2, 4.0, 24.0, 1.0, 15.0, 1.0, 10.0]           |\n",
      "+---------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_recipes_df.select('nutrition').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384f0ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing square brackets and string characters using replace function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1083715f",
   "metadata": {
    "id": "1083715f"
   },
   "outputs": [],
   "source": [
    "# Task 02 Cell 1 out of 2\n",
    "# 2.1 - string operations to remove square brakets\n",
    "\n",
    "raw_recipes_df = (raw_recipes_df\n",
    "                  .withColumn(\"nutrition\", F.regexp_replace(F.regexp_replace(F.regexp_replace(\"nutrition\", \"\\\\]\", \"\"), \"\\\\[\", \"\"), \"\\\\]\", \"\")\n",
    "                             # add code to remove square brackets\n",
    "                             # pyspark function to replace string characters \n",
    "                             ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d649df8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review after removing of brackets and string characters from nutrition column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "kKZQkCFkf3-7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kKZQkCFkf3-7",
    "outputId": "5c1ababa-f906-4de5-8b18-152320728975"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+\n",
      "|nutrition                                        |\n",
      "+-------------------------------------------------+\n",
      "|51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0              |\n",
      "|173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0          |\n",
      "|269.8, 22.0, 32.0, 48.0, 39.0, 27.0, 5.0         |\n",
      "|368.1, 17.0, 10.0, 2.0, 14.0, 8.0, 20.0          |\n",
      "|352.9, 1.0, 337.0, 23.0, 3.0, 0.0, 28.0          |\n",
      "|160.2, 10.0, 55.0, 3.0, 9.0, 20.0, 7.0           |\n",
      "|380.7, 53.0, 7.0, 24.0, 6.0, 24.0, 6.0           |\n",
      "|1109.5, 83.0, 378.0, 275.0, 96.0, 86.0, 36.0     |\n",
      "|4270.8, 254.0, 1306.0, 111.0, 127.0, 431.0, 220.0|\n",
      "|2669.3, 160.0, 976.0, 107.0, 62.0, 310.0, 138.0  |\n",
      "|79.2, 3.0, 58.0, 0.0, 0.0, 6.0, 5.0              |\n",
      "|734.1, 66.0, 199.0, 10.0, 10.0, 117.0, 28.0      |\n",
      "|462.4, 28.0, 214.0, 69.0, 14.0, 29.0, 23.0       |\n",
      "|315.8, 0.0, 202.0, 9.0, 6.0, 0.0, 21.0           |\n",
      "|8.2, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0                |\n",
      "|105.7, 8.0, 0.0, 26.0, 5.0, 4.0, 3.0             |\n",
      "|94.0, 10.0, 0.0, 11.0, 11.0, 21.0, 0.0           |\n",
      "|232.7, 21.0, 77.0, 4.0, 6.0, 38.0, 8.0           |\n",
      "|395.4, 31.0, 20.0, 29.0, 51.0, 33.0, 8.0         |\n",
      "|174.2, 4.0, 24.0, 1.0, 15.0, 1.0, 10.0           |\n",
      "+-------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_recipes_df.select('nutrition').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kvm9ySj2f4Eg",
   "metadata": {
    "id": "Kvm9ySj2f4Eg"
   },
   "outputs": [],
   "source": [
    "# split the nutrition string into seven individial values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fda7e9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of nutrition columns\n",
    "\n",
    "nutrition_column_names = ['calories',\n",
    "                          'total_fat_PDV',\n",
    "                          'sugar_PDV',\n",
    "                          'sodium_PDV',\n",
    "                          'protein_PDV',\n",
    "                          'saturated_fat_PDV',\n",
    "                          'carbohydrates_PDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c2a3cc8",
   "metadata": {
    "id": "7c2a3cc8"
   },
   "outputs": [],
   "source": [
    "# Task 02 Cell 2 out of 3\n",
    "# STEP 2.2 - split the neutrition string into seven individial values. \n",
    "# Create an object to split the nutrition column\n",
    "\n",
    "nutrition_cols_split = F.split(raw_recipes_df['nutrition'],',')\n",
    "# pyspark function to split values based on a delimiter.  \n",
    "\n",
    "# Write a loop to extract individual values from the nutrition column\n",
    "\n",
    "for col_index, col_name in enumerate(nutrition_column_names): # col_index holds the index number of each column, e.g., calories will be 0\n",
    "    # col_name holds the name of each column \n",
    "    \n",
    "    raw_recipes_df = (raw_recipes_df.withColumn(col_name, nutrition_cols_split.getItem(col_index).cast(\"float\")\n",
    "                                        # pyspark function to extract individual values from the nutrition_cols_split object\n",
    "                                        # You can also cast the extracted value to floats in the same code. \n",
    "                                               ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "MrgUShrsh2Wm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MrgUShrsh2Wm",
    "outputId": "f512ea50-8203-40c6-abe9-0a3874bcbb0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      " |-- minutes: integer (nullable = true)\n",
      " |-- contributor_id: integer (nullable = true)\n",
      " |-- submitted: string (nullable = true)\n",
      " |-- tags: string (nullable = true)\n",
      " |-- nutrition: string (nullable = true)\n",
      " |-- n_steps: integer (nullable = true)\n",
      " |-- steps: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- ingredients: string (nullable = true)\n",
      " |-- n_ingredients: integer (nullable = true)\n",
      " |-- calories: float (nullable = true)\n",
      " |-- total_fat_PDV: float (nullable = true)\n",
      " |-- sugar_PDV: float (nullable = true)\n",
      " |-- sodium_PDV: float (nullable = true)\n",
      " |-- protein_PDV: float (nullable = true)\n",
      " |-- saturated_fat_PDV: float (nullable = true)\n",
      " |-- carbohydrates_PDV: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_recipes_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3K18s1K5simp",
   "metadata": {
    "id": "3K18s1K5simp"
   },
   "outputs": [],
   "source": [
    "Write a loop to extract individual values from the nutrition column, col_index holds the index number of each column, e.g., calories will be 0,col_name holds the name of each column\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a87304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking assert commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88e62c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FloatType"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_recipes_df.schema[\"carbohydrates_PDV\"].dataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9eec0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "62.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_recipes_df.collect()[123432][14]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056898fa",
   "metadata": {
    "id": "056898fa"
   },
   "source": [
    "Hint: [Visit this page to learn more about splitting columns](https://sparkbyexamples.com/pyspark/pyspark-split-dataframe-column-into-multiple-columns/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4763390d",
   "metadata": {
    "id": "4763390d"
   },
   "source": [
    "**Test cases for task 02**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ab77b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking assert commands for above changes done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7323e7ff",
   "metadata": {
    "id": "7323e7ff",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Code check cell\n",
    "# Do not edit cells with assert commands\n",
    "# If an error is shown after running this cell, please recheck your code.  \n",
    "\n",
    "assert raw_recipes_df.schema[\"carbohydrates_PDV\"].dataType == FloatType(), \"Recheck your typecasting\"\n",
    "assert raw_recipes_df.collect()[123432][14] == 62.0, \"The columns have not been split correctly.\"\n",
    "assert raw_recipes_df.collect()[10000][12] == 60.400001525878906, \"The columns have not been split correctly.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c7c87c",
   "metadata": {
    "id": "e2c7c87c"
   },
   "source": [
    " #### <font color='red'>If all test cases pass task 02 ends </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb0277c",
   "metadata": {
    "id": "0eb0277c"
   },
   "source": [
    "## Make nutrition-per-100 calorie columns\n",
    "\n",
    "By converting the nutrition values from absolute to relative terms, we ensure that portion size is not a factor in the analysis. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac526a5",
   "metadata": {
    "id": "8ac526a5"
   },
   "source": [
    "Naming convention: Original column name ```total fat (PDV)```, column name after column ```total_fat_per_100_cal```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55662bc0",
   "metadata": {
    "id": "55662bc0"
   },
   "source": [
    "## <font color='red'>Task 03: Standardize the nutrition values </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dd54ed",
   "metadata": {
    "id": "28dd54ed"
   },
   "source": [
    "<font color='red'>\n",
    "The current values for nutrition columns are not on the same scale. \n",
    "Your task is to standardize the nutrition columns using calories as the base of standardization. \n",
    "\n",
    "Convert the nutrition from absolute values to per 100 calorie values. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ca70f8",
   "metadata": {
    "id": "40ca70f8"
   },
   "source": [
    "<font color='red'>\n",
    "    \n",
    "We will use the  ```sugar (PDV)``` column to demonstrate the calculations for standardization.  \n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892a8590",
   "metadata": {
    "id": "892a8590"
   },
   "source": [
    "![task3.01.png](attachment:task3.01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22596e49",
   "metadata": {
    "id": "22596e49"
   },
   "source": [
    "<font color='red'>\n",
    "    \n",
    "**Sample Calculation**\n",
    "\n",
    "Before transformation: ```sugar (PDV)``` for recipe id 137739 = 13.0\n",
    "\n",
    "Calories in the recipe recipe id 137739                       = 51.5\n",
    "\n",
    "Calculation:  \n",
    "sugar_per_100_cal = 13.0 * 100 / 51.5 \n",
    "\n",
    "After transformation ```sugar_per_100_cal``` = 25.24\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3347a9de",
   "metadata": {
    "id": "3347a9de"
   },
   "source": [
    "<font color='red'>\n",
    "\n",
    "**Sample Input:** \n",
    "\n",
    "All nutrition columns except calories\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ffc6fe",
   "metadata": {
    "id": "92ffc6fe"
   },
   "source": [
    "![task3.02.png](attachment:task3.02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fff4ea7",
   "metadata": {
    "id": "2fff4ea7"
   },
   "source": [
    "<font color='red'>\n",
    "\n",
    "**Sample Output:** \n",
    "\n",
    "All nutrition columns standardized to per 100 calories \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3306ed5",
   "metadata": {
    "id": "d3306ed5"
   },
   "source": [
    "![task3.03.png](attachment:task3.03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b542d1c1",
   "metadata": {
    "id": "b542d1c1"
   },
   "source": [
    "<font color='red'> We have included some test cases given below. You can use them to check if you have completed the task correctly.  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3affae2f",
   "metadata": {
    "id": "3affae2f"
   },
   "source": [
    "### <font color='blue'>Solution to Task 3 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ee388a",
   "metadata": {
    "id": "56ee388a"
   },
   "source": [
    "<font color='blue'>Complete the code in the following cell</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85f1ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating loop over each of the newly created nutrition columns, transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "237faab1",
   "metadata": {
    "id": "237faab1"
   },
   "outputs": [],
   "source": [
    "# Task 03 Cell 1 out of 1\n",
    "\n",
    "for new_nutrition_col in nutrition_column_names:# loop over each of the newly created nutrition columns \n",
    "    if new_nutrition_col != \"calories\":# the calories column should not be a part of the transformation exercise\n",
    "        # following code will name the new columns \n",
    "        nutrition_per_100_cal_col = (new_nutrition_col\n",
    "                                 .replace('_PDV','')\n",
    "                                 +'_per_100_cal')\n",
    "        raw_recipes_df = raw_recipes_df.withColumn(nutrition_per_100_cal_col,raw_recipes_df[new_nutrition_col]*100/raw_recipes_df[\"calories\"])\n",
    "                                               # pyspark code to recreate the intended transformation \n",
    "                                                  \n",
    "        \n",
    "        # You might end up adding nulls to the data because of our intended transformation. \n",
    "        # Perform a fill na operation to fill all the nulls with 0s. \n",
    "        # You must limit the scope of the fill na to the current column only. \n",
    "        \n",
    "        raw_recipes_df = raw_recipes_df.fillna(value=0,subset=[nutrition_per_100_cal_col]) # pyspark code to fill nulls with 0 in only the current nutrition_per_100_cal_col \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2656a22",
   "metadata": {
    "id": "d2656a22"
   },
   "source": [
    "**Test cases for Task 03**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dad04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation with assert commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "170ab190",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_recipes_df.filter(\"id == 28881\").select('total_fat_per_100_cal').first()[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d866fd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(raw_recipes_df.filter(\"id == 112140\").select('total_fat_per_100_cal').first()[0]) == 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a97ad4c",
   "metadata": {
    "id": "8a97ad4c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# total fat check for id 28881\n",
    "assert raw_recipes_df.filter(\"id == 28881\").select('total_fat_per_100_cal').first()[0] == 0, \"total_fat_per_100_cal for recipe 28881 should be 0\"\n",
    "\n",
    "# total fat check for id 112140\n",
    "assert round(raw_recipes_df.filter(\"id == 112140\").select('total_fat_per_100_cal').first()[0]) == 8, \"total_fat_per_100_cal for recipe 112140 should be 8\"\n",
    "\n",
    "# checking for nulls\n",
    "for c in ['total_fat_per_100_cal','sugar_per_100_cal','sodium_per_100_cal','protein_per_100_cal',\n",
    "                          'saturated_fat_per_100_cal','carbohydrates_per_100_cal']:\n",
    "    assert raw_recipes_df.select(F.count(F.when(F.isnan(c) | F.col(c).isNull(), c)).alias(c)).collect()[0][0] == 0, \"There are Nulls in the data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b2b456",
   "metadata": {
    "id": "77b2b456"
   },
   "source": [
    " #### <font color='red'>If all test cases pass task 03 ends </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd6ac1d",
   "metadata": {
    "id": "2bd6ac1d"
   },
   "source": [
    "## <font color='red'>Task 04: Convert the tags column from a string to an array of strings </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41905c76",
   "metadata": {
    "id": "41905c76"
   },
   "source": [
    "<font color='red'>\n",
    "    \n",
    "Currently, the tags column is a string column but holds an array of strings. \n",
    "\n",
    "Your task is to convert the tags columns from a string to an array of strings. \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08470494",
   "metadata": {
    "id": "08470494"
   },
   "source": [
    "<font color='red'>\n",
    "\n",
    "Remove ```[``` ```]``` ```'``` punctuation marks from the tags column. \n",
    "Split the tags column based on the comma delimiter. \n",
    "    \n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b724846",
   "metadata": {
    "id": "4b724846"
   },
   "source": [
    "<font color='red'>\n",
    "\n",
    "**Sample input**\n",
    "    \n",
    "Tags column in string datatype. \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c53092",
   "metadata": {
    "id": "61c53092"
   },
   "source": [
    "![task4.01.png](attachment:task4.01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d04cf2",
   "metadata": {
    "id": "d8d04cf2"
   },
   "source": [
    "<font color='red'>\n",
    "\n",
    "**Sample outout**\n",
    "    \n",
    "Tags column in array of ArrayType(StringType())  \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22614b82",
   "metadata": {
    "id": "22614b82"
   },
   "source": [
    "![task4.02.png](attachment:task4.02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fe1ba7",
   "metadata": {
    "id": "e7fe1ba7"
   },
   "source": [
    "<font color='red'> We have included some test cases given below. You can use them to check if you have completed the task correctly.  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7580844",
   "metadata": {
    "id": "a7580844"
   },
   "source": [
    "### <font color='blue'>Solution to Task 4 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98593e1f",
   "metadata": {
    "id": "98593e1f"
   },
   "source": [
    "<font color='blue'>Complete the code in the following cell</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b33737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing Tags column in array of ArrayType(StringType()), Splitting the tags column based on the comma delimiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c749ab84",
   "metadata": {
    "id": "c749ab84"
   },
   "outputs": [],
   "source": [
    "# Task 04 Cell 1 out of 1\n",
    "\n",
    "raw_recipes_df = (raw_recipes_df\n",
    "                  .withColumn('tags', F.regexp_replace('tags',\"[\\[\\\\]\\']\", \"\") \n",
    "                             # pyspark function to remove symbols like '[' ']' \"'\" from the strings in the tags column.\n",
    "                             )\\\n",
    "                  .withColumn('tags',F.split(F.col('tags'),', ') \n",
    "                             # pyspark function to split the column using the comma delimiter.\n",
    "                             ))\n",
    "\n",
    "\n",
    "#raw_recipes_df = (raw_recipes_df.withColumn('tags', F.regexp_replace('tags', \"\\]\\\", \"\"), \"\\[\\\", \"\",\"\\]\\\", \"\")\n",
    "                             # pyspark function to remove symbols like '[' ']' \"'\" from the strings in the tags column.\n",
    "                             \n",
    "                 #.withColumn('tags', F.regexp_replace('tags', '\\]\\', '')\n",
    "                             # pyspark function to remove symbols like '[' ']' \"'\" from the strings in the tags column.\n",
    "                             \n",
    "                 #.withColumn('tags', F.regexp_replace('tags', '\\'', '')\n",
    "                             # pyspark function to remove symbols like '[' ']' \"'\" from the strings in the tags column.\n",
    "                            # ))\n",
    "                              \n",
    "                             # pyspark function to remove symbols like '[' ']' \"'\" from the strings in the tags column.\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "KxouPCN-1-Z4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KxouPCN-1-Z4",
    "outputId": "63e0e1e7-d923-4eb4-ab59-5bddb609ea3f"
   },
   "outputs": [],
   "source": [
    "#from pyspark.sql.functions import col\n",
    "#raw_recipes_df1 = raw_recipes_df.select(F.split(col('tags'),',').alias('tag'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "Zh6UfNecss7F",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zh6UfNecss7F",
    "outputId": "59394932-9e4d-4e47-98a3-e5d56483a8c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_recipes_df.schema[\"tags\"].dataType == ArrayType(StringType(), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "qsbYPuvmNe8A",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qsbYPuvmNe8A",
    "outputId": "5c222b79-c29e-4da7-dcf7-2915d022c2f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      " |-- minutes: integer (nullable = true)\n",
      " |-- contributor_id: integer (nullable = true)\n",
      " |-- submitted: string (nullable = true)\n",
      " |-- tags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- nutrition: string (nullable = true)\n",
      " |-- n_steps: integer (nullable = true)\n",
      " |-- steps: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- ingredients: string (nullable = true)\n",
      " |-- n_ingredients: integer (nullable = true)\n",
      " |-- calories: float (nullable = true)\n",
      " |-- total_fat_PDV: float (nullable = true)\n",
      " |-- sugar_PDV: float (nullable = true)\n",
      " |-- sodium_PDV: float (nullable = true)\n",
      " |-- protein_PDV: float (nullable = true)\n",
      " |-- saturated_fat_PDV: float (nullable = true)\n",
      " |-- carbohydrates_PDV: float (nullable = true)\n",
      " |-- total_fat_per_100_cal: double (nullable = false)\n",
      " |-- sugar_per_100_cal: double (nullable = false)\n",
      " |-- sodium_per_100_cal: double (nullable = false)\n",
      " |-- protein_per_100_cal: double (nullable = false)\n",
      " |-- saturated_fat_per_100_cal: double (nullable = false)\n",
      " |-- carbohydrates_per_100_cal: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_recipes_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abea8362",
   "metadata": {
    "id": "abea8362"
   },
   "source": [
    "**Test cases for Task 04**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "493f28b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "493f28b6",
    "outputId": "475ff9f8-0b2b-4f8b-dd8f-695ad507f41d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Code check cell\n",
    "# Do not edit cells with assert commands\n",
    "# If an error is shown after running this cell, please recheck your code.  \n",
    "\n",
    "assert raw_recipes_df.schema[\"tags\"].dataType == ArrayType(StringType(), True), \"You have not split the string into an array.\"\n",
    "assert raw_recipes_df.collect()[2][5] == ['time-to-make','course', 'preparation', 'main-dish', 'chili', 'crock-pot-slow-cooker', 'dietary', 'equipment', '4-hours-or-less'], \"Recheck your string cleaning and splitting operations.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923e5db1",
   "metadata": {
    "id": "923e5db1"
   },
   "source": [
    "#### <font color='red'>If all test cases pass task 04 ends </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e3185b",
   "metadata": {
    "id": "96e3185b"
   },
   "source": [
    "## Join Recipe Data to Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab81555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading second data set raw_ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63fba4f5",
   "metadata": {
    "id": "63fba4f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Reading the second data set. \n",
    "# keep this cell unedited\n",
    "\n",
    "raw_ratings_df = (spark.read.csv(\"RAW_interactions_cleaned.csv\",header=True,inferSchema= True)\n",
    "                  .withColumn(\"review_date\",  F.col(\"date\"))\n",
    "                  .drop(F.col(\"date\"))\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31b18096",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31b18096",
    "outputId": "8e62c5de-320a-4956-f628-c7d903cc8b81",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- recipe_id: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      " |-- review: string (nullable = true)\n",
      " |-- review_date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_ratings_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01d4e1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1132367"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_ratings_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb408370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_ratings_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4e8cac9",
   "metadata": {
    "id": "f4e8cac9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Code check cell\n",
    "# Do not edit cells with assert commands\n",
    "# If an error is shown after running this cell, please recheck your code.  \n",
    "\n",
    "assert raw_ratings_df.count() == 1132367, \"There is a mistake in reading the data.\"\n",
    "assert len(raw_ratings_df.columns) == 5, \"There is a mistake in reading the data.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "17084afb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17084afb",
    "outputId": "b48c023c-414b-4359-ef3a-514cf8a8ce14",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+--------------------+-----------+\n",
      "|user_id|recipe_id|rating|              review|review_date|\n",
      "+-------+---------+------+--------------------+-----------+\n",
      "|  38094|    40893|     4|Great with a sala...| 2003-02-17|\n",
      "|1293707|    40893|     5|So simple  so del...| 2011-12-21|\n",
      "|   8937|    44394|     4|This worked very ...| 2002-12-01|\n",
      "| 126440|    85009|     5|I made the Mexica...| 2010-02-27|\n",
      "|  57222|    85009|     5|Made the cheddar ...| 2011-10-01|\n",
      "+-------+---------+------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_ratings_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6335b6",
   "metadata": {
    "id": "9e6335b6"
   },
   "source": [
    "## <font color='red'>Task 05: Read the second data file </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb38527e",
   "metadata": {
    "id": "bb38527e"
   },
   "source": [
    "<font color='red'>\n",
    "\n",
    "Along with raw recipes data, we also have raw ratings data. \n",
    "\n",
    "The code to read the data is already written above. Your task is to join the raw ratings and raw recipes data. \n",
    "\n",
    "The resulting dataframe must have the same number of rows as in the raw ratings data. \n",
    "    \n",
    "Join both the dataframes using the recipie IDs.\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe730a0",
   "metadata": {
    "id": "afe730a0"
   },
   "source": [
    "<font color='red'>\n",
    "    \n",
    "**Sample Input**\n",
    "    \n",
    "```raw recipes_df``` and ```raw_ratings_df```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874180c3",
   "metadata": {
    "id": "874180c3"
   },
   "source": [
    "![task5.01.png](attachment:task5.01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5408d705",
   "metadata": {
    "id": "5408d705"
   },
   "source": [
    "<font color='red'>\n",
    "\n",
    "**Sample Output**\n",
    "\n",
    "Combined dataframe with 30 columns and 1132367 rows \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f83c600",
   "metadata": {
    "id": "4f83c600"
   },
   "source": [
    "![task5.02.png](attachment:task5.02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f4fe5a",
   "metadata": {
    "id": "e7f4fe5a"
   },
   "source": [
    "<font color='red'>\n",
    "\n",
    "**Calculation explanation** \n",
    "\n",
    "There are 25 columns in the ```raw_recipes_df``` and five in the ```raw_ratings_df```. So total columns in the combined dataframe 25 + 5 = 30\n",
    "\n",
    "The number of rows in the combined dataframe must be the same as the rows in the ```raw_ratings_df```. So total rows in combined dataframe 1132367\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7c934d",
   "metadata": {
    "id": "dc7c934d"
   },
   "source": [
    "<font color='red'> We have included some test cases given below. You can use them to check if you have completed the task correctly.  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f87f2f0",
   "metadata": {
    "id": "4f87f2f0"
   },
   "source": [
    "### <font color='blue'>Solution to Task 5 </font>\n",
    "\n",
    "<font color='blue'>Complete the code in the following cell</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75df98cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new df = interaction_level_df by joining raw_recipes_df data set and raw_ratings_df data set using left join. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "800f2ecc",
   "metadata": {
    "id": "800f2ecc"
   },
   "outputs": [],
   "source": [
    "# Task 05 Cell 1 out of 1\n",
    "\n",
    "interaction_level_df = raw_ratings_df.join(raw_recipes_df, raw_ratings_df.recipe_id == raw_recipes_df.id, 'left'\n",
    "                                           # add the key on which the join should happen\n",
    "                                           # mention the type of join expected. \n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b939876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1132367"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_level_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76f74093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(interaction_level_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a20faf3",
   "metadata": {
    "id": "1a20faf3"
   },
   "source": [
    "**Test cases for Task 05**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a59d3cb",
   "metadata": {
    "id": "7a59d3cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Code check cell\n",
    "# Do not edit cells with assert commands\n",
    "# If an error is shown after running this cell, please recheck your code.  \n",
    "\n",
    "assert (interaction_level_df.count() ,len(interaction_level_df.columns)) == (1132367, 30), \"The type of join is incorrect\"\n",
    "\n",
    "list1 = raw_ratings_df.select('recipe_id').collect()\n",
    "list2 = raw_recipes_df.select('id').collect()\n",
    "exclusive_set = set(list1)-set(list2)\n",
    "\n",
    "assert len(exclusive_set) == 0, \"There is a mistake in reading one of the two data files.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b84f908",
   "metadata": {
    "id": "0b84f908"
   },
   "source": [
    "#### <font color='red'>If all test cases pass task 05 ends </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470302a4",
   "metadata": {
    "id": "470302a4"
   },
   "source": [
    "## <font color='red'>Task 06:  Create time-based features</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a69cd3",
   "metadata": {
    "id": "41a69cd3"
   },
   "source": [
    "<font color='red'>\n",
    "\n",
    "Currently, both the date columns, the submitted date, and the review date are in string forms. \n",
    "    \n",
    "First convert the ```submitted``` and ```review_date``` to DateType()\n",
    "\n",
    "Use review date and submission date to derive new features:\n",
    "1. ```days_since_submission_on_review_date``` Number of days between the recipe submission and the current review.  \n",
    "2. ```months_since_submission_on_review_date``` Number of months between the recipe submission and the current review. \n",
    "3. ```years_since_submission_on_review_date```Number of years between the recipe submission and the current review. \n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72e2573",
   "metadata": {
    "id": "a72e2573"
   },
   "source": [
    "<font color='red'>\n",
    "\n",
    "**Sample input**\n",
    "\n",
    "The following columns need to be used to calculate the time based features. \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538e9195",
   "metadata": {
    "id": "538e9195"
   },
   "source": [
    "![task6.01.png](attachment:task6.01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34178367",
   "metadata": {
    "id": "34178367"
   },
   "source": [
    "<font color='red'>\n",
    "\n",
    "**Sample Output:**\n",
    "\n",
    "New date based features have been added to the interactions dataframe\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82adcc3c",
   "metadata": {
    "id": "82adcc3c"
   },
   "source": [
    "![task6.02.png](attachment:task6.02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d410639",
   "metadata": {
    "id": "3d410639"
   },
   "source": [
    "<font color='red'>\n",
    "\n",
    "**Sample Calculation**\n",
    "\n",
    "Recipe 40893 was submitted on 2002-09-21\n",
    "User 38094 reviewed recipe 40893 on 2003-02-17\n",
    "\n",
    "```days_since_submission_on_review_date``` number of calender days between 2002-09-21 and 2003-02-17 that is 149\n",
    "\n",
    "```months_since_submission_on_review_date``` number of calender months between 2002-09-21 and 2003-02-17 that is 4.87 (calculated by a pyspark function)\n",
    "\n",
    "```years_since_submission_on_review_date``` number of calender months divided by 12 that is 0.40\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc67d3ac",
   "metadata": {
    "id": "dc67d3ac"
   },
   "source": [
    "### <font color='blue'>Solution to Task 6 </font>\n",
    "\n",
    "<font color='blue'>Complete the code in the following cell</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f801f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type casting a column to DateType()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4325e82b",
   "metadata": {
    "id": "4325e82b"
   },
   "outputs": [],
   "source": [
    "# Task 06 Cell 1 out of 2\n",
    "\n",
    "interaction_level_df = (interaction_level_df\n",
    "                        .withColumn('submitted',F.col(\"submitted\").cast(\"date\") \n",
    "                        # pyspark function to cast a column to DateType()\n",
    "                                   )\n",
    "                        .withColumn('review_date',F.col(\"review_date\").cast(\"date\") \n",
    "                        # pyspark function to cast a column to DateType()\n",
    "                                   )\n",
    "                                             \n",
    "                       )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491f8df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the number of days between two dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dc2f5452",
   "metadata": {
    "id": "dc2f5452",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interaction_level_df = (interaction_level_df\n",
    "                        .withColumn('days_since_submission_on_review_date',F.datediff(\"review_date\",\"submitted\")\n",
    "                                     # Pyspark function to find the number of days between two dates              \n",
    "                                  )\n",
    "                        .withColumn('months_since_submission_on_review_date',F.months_between(\"review_date\",\"submitted\")\n",
    "                                     # Pyspark function to find the number of months between two dates          \n",
    "                                   )\n",
    "                        .withColumn('years_since_submission_on_review_date',F.months_between(\"review_date\",\"submitted\")/12\n",
    "                                     # Pyspark function to find the number of months between two dates / 12          \n",
    "                                   )\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32301322",
   "metadata": {
    "id": "32301322"
   },
   "source": [
    "**Test cases for Task 06**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "416eb59e",
   "metadata": {
    "id": "416eb59e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Code check cell\n",
    "# Do not edit cells with assert commands\n",
    "# If an error is shown after running this cell, please recheck your code.  \n",
    "\n",
    "assert interaction_level_df.schema[\"days_since_submission_on_review_date\"].dataType == IntegerType()\n",
    "\n",
    "assert (interaction_level_df.filter((interaction_level_df.user_id == 428885) & (interaction_level_df.recipe_id == 335241))\n",
    "                            .select('days_since_submission_on_review_date').collect()[0][0]) == 77\n",
    "assert (interaction_level_df.filter((interaction_level_df.user_id == 2025676) & (interaction_level_df.recipe_id == 94265))\n",
    "                            .select('months_since_submission_on_review_date').collect()[0][0]) == 153.22580645\n",
    "assert (interaction_level_df.filter((interaction_level_df.user_id == 338588) & (interaction_level_df.recipe_id == 21859))\n",
    "                            .select('years_since_submission_on_review_date').collect()[0][0]) == 4.564516129166667"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a764c83",
   "metadata": {
    "id": "3a764c83"
   },
   "source": [
    "#### <font color='red'>If all test cases pass task 06 ends</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794e0e3e",
   "metadata": {
    "id": "794e0e3e"
   },
   "source": [
    "## Save the data we have created so far in a parquet file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24f6017a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24f6017a",
    "outputId": "e3b4a08a-8336-42ee-9774-8ef49ecdbdab",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- recipe_id: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      " |-- review: string (nullable = true)\n",
      " |-- review_date: date (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      " |-- minutes: integer (nullable = true)\n",
      " |-- contributor_id: integer (nullable = true)\n",
      " |-- submitted: date (nullable = true)\n",
      " |-- tags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- nutrition: string (nullable = true)\n",
      " |-- n_steps: integer (nullable = true)\n",
      " |-- steps: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- ingredients: string (nullable = true)\n",
      " |-- n_ingredients: integer (nullable = true)\n",
      " |-- calories: float (nullable = true)\n",
      " |-- total_fat_PDV: float (nullable = true)\n",
      " |-- sugar_PDV: float (nullable = true)\n",
      " |-- sodium_PDV: float (nullable = true)\n",
      " |-- protein_PDV: float (nullable = true)\n",
      " |-- saturated_fat_PDV: float (nullable = true)\n",
      " |-- carbohydrates_PDV: float (nullable = true)\n",
      " |-- total_fat_per_100_cal: double (nullable = true)\n",
      " |-- sugar_per_100_cal: double (nullable = true)\n",
      " |-- sodium_per_100_cal: double (nullable = true)\n",
      " |-- protein_per_100_cal: double (nullable = true)\n",
      " |-- saturated_fat_per_100_cal: double (nullable = true)\n",
      " |-- carbohydrates_per_100_cal: double (nullable = true)\n",
      " |-- days_since_submission_on_review_date: integer (nullable = true)\n",
      " |-- months_since_submission_on_review_date: double (nullable = true)\n",
      " |-- years_since_submission_on_review_date: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "interaction_level_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "864a70a2",
   "metadata": {
    "id": "864a70a2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "assert (interaction_level_df.count() ,len(interaction_level_df.columns) ) == (1132367, 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f66d1048",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "813533e7334742f2bcea0365f20888c9",
      ""
     ]
    },
    "id": "f66d1048",
    "outputId": "344ac0ef-72c6-4b2f-f3ab-aa5670675418"
   },
   "outputs": [],
   "source": [
    "\n",
    "#interaction_level_df.write\n",
    "#                    .mode('overwrite').parquet('data/interaction_level_df_processed.parquet') # Modify the path as you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1cdab1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/23 07:35:00 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "## Write the raw_recipes_df\n",
    "## create a folder named data in you current directry before running this. \n",
    "\n",
    "interaction_level_df.write.mode(\"overwrite\").parquet(\"data-interaction_level_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019a9cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
